---
title: "AI and AML"
date: 2024-02-14
description: "Get started with ai-models within KYC and AML"
tags:
  - other
last_updated_by: Mats
image_url: /assets/img/aml.png
published: true
---

**AI and AML**

To work with a risk-based approach in Know Your Customer(KYC), Anti money laundering(AML) or Transaction Monitoring, continuous screening and risk assessments are performed. These are based on predefined levels of risk tolerance, which are reflected in various ways across different IT systems.

The result is a risk-based approach where a large number of cases can be handled automatically, but there are also cases that require more in-depth, and possibly manual, handling.

This entire setup meets the requirements from regulatory bodies for a risk-based approach. It emphasizes spending time on matters that are worth the effort.

The values used to match these thresholds or breakpoints can be referred to as rank, rating, points, risk points, etc. The levels are usually set with a margin so that the systems and processes are risk-averse. It's preferable to check too many than to make a mistake. All these warnings that require extra manual investigations and controls are often called false positives. A recurring theme is to reduce false positives (trying to make the systems more accurate). At the same time, there's a notion that having false positives is necessary to be sufficiently risk-averse. No false positives must mean something is missed.

<img src="/assets/img/people.png" />
<br/>

Of course, everything depends on the quality of the process. How well the systems are designed to filter out the real cases compared to those where it's obvious upon review that no further investigation is needed.

**Improvement potential**

Established technology and systems (systems, code, and formulas designed to detect hits) have resulted in several percent of false positives, maybe 3-5%, 10%, or 15%. Reducing this amount is a difficult balance and requires continuous work and deep domain insight. Simply validating new software that decreases the number of false positives by a few percent can be a significant and challenging task.

However, recent developments in machine learning and AI have provided us with entirely new tools that can elevate these processes to entirely new levels. To understand the significant difference this can make compared to the past, one only needs to look at how images can be generated by generative models. The development has exploded. It all builds on new faster computers, new architecture with GPUs that make it possible to perform the incredibly large number of calculations required to achieve these results.

Now that the hardware and technology are available, shouldn't the development within KYC, AML, sanction screening, and monitoring improve tenfold or even a hundredfold? Yes, development is happening, but it's slightly hampered by uncertainty around the technology and the difficulty in making decisions on such advanced models where it's hard to explain exactly how decisions are made. This is certainly a problem, but it shouldn't hinder progress. 

**Opportunities**

There are numerous ways to use modern models in the field without leaving the bulk of monitoring and screening to the models. Here are some examples of areas where modern computing power and AI models should make a significant difference:

- Test data generation using generative models. These models excel at creating large datasets that closely resemble real data, without actually being real data. This allows for the testing of IT development systems with fictitious data on the same scale as in production. 
- Explaining and supporting manual work where complex but structured regulations form the basis. For example, automatically describing, in simple text, how a transaction type is used directly for the operator of the screening or monitoring systems.
- Using models to analyze large datasets for IT system quality control. For instance, in validations of code changes or upgrades. Compare monitoring results before and after a change and use models for anomaly detection.
- Using models to analyze large datasets for data quality control. Then use generative models for data improvement, either through metadata enrichment or simply by analyzing datasets to find anomalies. Ensure the data is in its best form.
- Of course, in monitoring and screening tools where reduction of false positives is desired. Not entirely automatically but as an add-on for operators so decisions can be made faster.
- Automatic solutions to help out in classifing between risky behaviour and lack of KYC due to missunderstanding, lack of knowledge or accessability to digital channels.
- Any other ideas? Let us know!

Posten kommer p√• svenska inom kort. 
Athega delivers AI solutions.


